{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libaries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('feature_dataset/NYC_data.csv')\n",
    "# drop Nan\n",
    "df = df.dropna(axis = 1)\n",
    "\n",
    "# drop useless feature and symbols\n",
    "df.drop(columns=['SentimentScore.1','Neighborhood','Board','Index of housing price appreciation, 1 family building','Index of housing price appreciation, 2-4 family building','Index of housing price appreciation, 5+ family building','Index of housing price appreciation, condominium','Index of housing price appreciation, all property types'], inplace=True)\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].map(lambda x: ''.join(filter(str.isdigit, x)) if isinstance(x, str) else x)\n",
    "X = df.drop(columns = ['SentimentScore'])\n",
    "y = df['SentimentScore'].rank(ascending=False, method='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  # for debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual RMSEs: [25.40534262040839, 28.719464309850878, 9.625950555577333, 1.886607923147949, 55.01929161565471, 0.7627129326444333, 12.386477589499577, 15.437786324996466, 16.662434726809863, 19.95705756274839, 17.811876967711243, 76.7836466431844, 44.42657509322669, 146.34017117376249, 85.80094020434734, 0.1380681402044388, 3.4270987842775185, 25.74909719409311, 19.377212865938418, 20.974602318745937, 26.896803663085166, 63.46363250360912, 16.676997093817363, 23.974771094944856]\n",
      "Mean RMSE: 31.571025829261924\n",
      "Weights (Coefficients): [-0.006407502817827284, -0.000441852220629118, 0.0006417758801631978, -0.0005267275991136151, -0.0046306790800415415, -0.00020850561142950294, 0.0029584201429184546, 0.005489645193283423, -0.0058712230222778055, 0.0016590640278298832, -0.008567705912449397, 0.0016288220925649993, 0.0009839553054340241, 0.0009096939826755653, 0.0013459341030587215, -0.0003100852051924702, -0.0017992124505995634, 0.006003476119283545, 0.003612712892085592, -0.001482857191159912, 0.000474324225762451, 0.0038328170474348456, -0.003215714251586564, -0.003497809482989227]\n",
      "Intercepts: [-232.8462601605469, -411.8849098776417, -478.7604909536814, -494.37085627154664, -445.32378770987253, -507.3748282331888, -476.1520169191844, -215.94122000737747, -282.95401253625465, -359.7383813984602, -118.55326942270815, -621.0666061560222, -474.253725061973, -472.6217447040115, -533.7507733960992, -505.656219657985, -443.2139707540818, -557.9315454838455, -494.94338482565536, -104.07944948841296, -109.60040476271175, -603.5238252921689, -516.2142985686153, -442.5704715932637]\n"
     ]
    }
   ],
   "source": [
    "# Leave-One-Out Cross-Validation \n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# define model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "\n",
    "# list to calculate RSME\n",
    "errors = []\n",
    "weights = []  \n",
    "intercepts = []  \n",
    "\n",
    "# loop to do the leave one out\n",
    "for train_index, test_index in loo.split(X):\n",
    "    # split the data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # learn the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    weights.append(model.coef_[0])  \n",
    "    intercepts.append(model.intercept_)\n",
    "    \n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # add the error to the list\n",
    "    error = np.sqrt(mean_squared_error(y_test, y_pred))  # RMSE\n",
    "    errors.append(error)\n",
    "\n",
    "# caculate the average\n",
    "mean_rmse = np.mean(errors)\n",
    "\n",
    "print(f\"Individual RMSEs: {errors}\")\n",
    "print(f\"Mean RMSE: {mean_rmse}\")\n",
    "print(f\"Weights (Coefficients): {weights}\")\n",
    "print(f\"Intercepts: {intercepts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual RMSEs: [12.165634669666005, 0.6314000750769964, 15.738514406291166, 5.184580085044587, 0.5884948143517761, 4.242825184588156, 18.067770744995798, 7.1535477481077265, 5.829209375471493, 18.909785791824874, 7.6945561014669295, 20.03539232494012, 4.505082041448389, 13.968638476062353, 14.066807393905094, 4.700194838655804, 5.925989712654584, 3.2131211353351574, 15.477142950852624, 7.359879412379513, 34.93402705041017, 5.099828139071036, 9.768161280914143, 10.547243232252185]\n",
      "Mean RMSE: 10.241992791073612\n",
      "Weights (Coefficients): [-0.39958734444851524, -0.14364462237600975, 0.024372678147059956, -0.11640346329510745, -0.18119389584742132, -0.2672573060480509, 0.0951794158670457, -0.5508108746267267, -0.2894361680700207, 0.12827772372656301, -0.3963142903210309, -0.06284449849095199, -0.15403217944133146, -0.14725933987172637, -0.09035073521846486, -0.216726382391264, -0.11993186115278119, -0.09561940663911914, -0.40722160528567614, 0.009460707666531655, -0.27218304194999815, -0.14527766903642408, 0.11746916964314487, -0.3282445953515559]\n",
      "Intercepts: [132.0301086421248, 125.964732661046, 51.203948609029226, 108.09626350282703, 127.73609616503929, 158.22476824149666, 95.05220597245301, 113.08393788621201, 171.22681207191192, 136.45535824581125, 156.91837669066652, 99.72596030516463, 139.06325197998763, 121.77294138939088, 106.11162370784143, 140.87140190067163, 144.7349847011655, 118.33017885939148, 194.48850566792865, 117.12605614384117, 94.40943371625418, 138.2412739936522, 91.30133858246055, 135.19065771599378]\n"
     ]
    }
   ],
   "source": [
    "# Leave-One-Out Cross-Validation \n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# define model\n",
    "from sklearn.linear_model import Lasso\n",
    "model = Lasso(alpha=1e-4)\n",
    "\n",
    "# list to calculate RSME\n",
    "errors = []\n",
    "weights = []  \n",
    "intercepts = []  \n",
    "\n",
    "# loop to do the leave one out\n",
    "for train_index, test_index in loo.split(X):\n",
    "    # split the data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # learn the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    weights.append(model.coef_[0])  \n",
    "    intercepts.append(model.intercept_)\n",
    "    \n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # add the error to the list\n",
    "    error = np.sqrt(mean_squared_error(y_test, y_pred))  # RMSE\n",
    "    errors.append(error)\n",
    "\n",
    "# caculate the average\n",
    "mean_rmse = np.mean(errors)\n",
    "\n",
    "print(f\"Individual RMSEs: {errors}\")\n",
    "print(f\"Mean RMSE: {mean_rmse}\")\n",
    "print(f\"Weights (Coefficients): {weights}\")\n",
    "print(f\"Intercepts: {intercepts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual RMSEs: [2.9800000000000004, 0.96, 0.14000000000000057, 1.9800000000000004, 2.79, 1.0300000000000002, 1.4499999999999993, 2.1700000000000017, 0.17999999999999972, 1.0199999999999996, 4.0, 0.6799999999999997, 1.1399999999999997, 0.6999999999999993, 1.1199999999999992, 0.0, 1.1900000000000013, 1.1500000000000004, 3.3000000000000007, 0.4200000000000017, 4.620000000000001, 0.9399999999999995, 1.9300000000000002, 2.66]\n",
      "Mean RMSE: 1.60625\n",
      "Feature Importances: [0.003341861515723032, 0.0015016244348558796, 0.0008067076793299138, 0.0018667413592107368, 0.004053191770122354, 0.0006962252004336594, 0.0009090257916979825, 0.0009925249981814117, 0.0006270872991323162, 0.001782456414689827, 0.0008582250608672148, 0.0018756693442621316, 0.0026453510697768763, 0.001972247700242685, 0.001501923069719098, 0.0005971542859680326, 0.000992176873849841, 0.0015574746764950996, 0.0015933509802558005, 0.001324239054928977, 0.0008403706410527468, 0.0020593605896341545, 0.0020103133048071055, 0.0019076643125462125]\n",
      "Predictions: [19.02, 7.04, 17.86, 14.98, 5.79, 4.97, 8.45, 18.17, 5.18, 18.98, 5.0, 8.32, 5.14, 14.7, 8.88, 19.0, 18.19, 13.85, 15.3, 20.58, 19.38, 11.94, 3.93, 20.34]\n"
     ]
    }
   ],
   "source": [
    "# Leave-One-Out Cross-Validation \n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# define model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# list to calculate RSME\n",
    "errors = []\n",
    "feature_importances = [] \n",
    "predictions = []  \n",
    "\n",
    "# loop to do the leave one out\n",
    "for train_index, test_index in loo.split(X):\n",
    "    # split the data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # learn the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    feature_importances.append(model.feature_importances_[0])\n",
    "    \n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions.append(y_pred[0])\n",
    "    \n",
    "    # add the error to the list\n",
    "    error = np.sqrt(mean_squared_error(y_test, y_pred))  # RMSE\n",
    "    errors.append(error)\n",
    "\n",
    "# caculate the average\n",
    "mean_rmse = np.mean(errors)\n",
    "\n",
    "print(f\"Individual RMSEs: {errors}\")\n",
    "print(f\"Mean RMSE: {mean_rmse}\")\n",
    "print(f\"Feature Importances: {feature_importances}\")\n",
    "print(f\"Predictions: {predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual RMSEs: [1.0, 1.0, 1.0, 5.0, 3.0, 4.0, 5.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0]\n",
      "Mean RMSE: 1.9166666666666667\n",
      "Predictions: [21.0, 7.0, 17.0, 18.0, 6.0, 2.0, 12.0, 17.0, 2.0, 22.0, 2.0, 12.0, 5.0, 15.0, 9.0, 20.0, 18.0, 13.0, 15.0, 20.0, 22.0, 10.0, 1.0, 24.0]\n"
     ]
    }
   ],
   "source": [
    "# Leave-One-Out Cross-Validation \n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# define model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# list to calculate RSME\n",
    "errors = []\n",
    "predictions = []  \n",
    "\n",
    "# loop to do the leave one out\n",
    "for train_index, test_index in loo.split(X):\n",
    "    # split the data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # learn the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions.append(y_pred[0])\n",
    "    \n",
    "    # add the error to the list\n",
    "    error = np.sqrt(mean_squared_error(y_test, y_pred))  # RMSE\n",
    "    errors.append(error)\n",
    "\n",
    "# caculate the average\n",
    "mean_rmse = np.mean(errors)\n",
    "\n",
    "print(f\"Individual RMSEs: {errors}\")\n",
    "print(f\"Mean RMSE: {mean_rmse}\")\n",
    "print(f\"Predictions: {predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual RMSEs: [9.98407410617398, 4.6446800312732055, 5.951383362824291, 0.9214433651036007, 9.753064589047481, 6.925674855882281, 5.969195041848987, 4.105022372911408, 7.899186547348963, 8.136168343594816, 11.892654799857457, 3.423485117859151, 8.543635813964077, 3.4827847442307824, 3.1383404280148994, 6.896426352645422, 5.011673403487233, 3.0116601412795436, 0.9214242338477892, 8.992543335633565, 12.115929230131185, 1.8633679824749674, 10.962464986946404, 10.929535834844248]\n",
      "Mean RMSE: 6.478159125884406\n",
      "Predictions: [12.01592589382602, 12.644680031273206, 12.048616637175709, 12.0785566348964, 12.753064589047481, 12.925674855882281, 12.969195041848987, 11.894977627088592, 12.899186547348963, 11.863831656405184, 12.892654799857457, 12.423485117859151, 12.543635813964077, 10.517215255769218, 13.1383404280149, 12.103573647354578, 11.988326596512767, 11.988339858720456, 12.92142423384779, 12.007456664366435, 11.884070769868815, 12.863367982474967, 12.962464986946404, 12.070464165155752]\n"
     ]
    }
   ],
   "source": [
    "# Leave-One-Out Cross-Validation \n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# define model\n",
    "from sklearn.svm import SVR\n",
    "model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "\n",
    "# list to calculate RSME\n",
    "errors = []\n",
    "predictions = []  \n",
    "\n",
    "# loop to do the leave one out\n",
    "for train_index, test_index in loo.split(X):\n",
    "    # split the data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # learn the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions.append(y_pred[0])\n",
    "    \n",
    "    # add the error to the list\n",
    "    error = np.sqrt(mean_squared_error(y_test, y_pred))  # RMSE\n",
    "    errors.append(error)\n",
    "\n",
    "# caculate the average\n",
    "mean_rmse = np.mean(errors)\n",
    "\n",
    "print(f\"Individual RMSEs: {errors}\")\n",
    "print(f\"Mean RMSE: {mean_rmse}\")\n",
    "print(f\"Predictions: {predictions}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
