{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libaries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('feature_dataset/NYC_data.csv')\n",
    "# drop Nan\n",
    "df = df.dropna(axis = 1)\n",
    "\n",
    "# drop useless feature and symbols\n",
    "df.drop(columns=['SentimentScore.1','Neighborhood','Board','Index of housing price appreciation, 1 family building','Index of housing price appreciation, 2-4 family building','Index of housing price appreciation, 5+ family building','Index of housing price appreciation, condominium','Index of housing price appreciation, all property types'], inplace=True)\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].map(lambda x: ''.join(filter(str.isdigit, x)) if isinstance(x, str) else x)\n",
    "X = df.drop(columns = ['SentimentScore'])\n",
    "y = df['SentimentScore'].rank(ascending=False, method='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  # for debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual RMSEs: [25.40534262040839, 28.719464309850878, 9.625950555577333, 1.886607923147949, 55.01929161565471, 0.7627129326444333, 12.386477589499577, 15.437786324996466, 16.662434726809863, 19.95705756274839, 17.811876967711243, 76.7836466431844, 44.42657509322669, 146.34017117376249, 85.80094020434734, 0.1380681402044388, 3.4270987842775185, 25.74909719409311, 19.377212865938418, 20.974602318745937, 26.896803663085166, 63.46363250360912, 16.676997093817363, 23.974771094944856]\n",
      "Mean RMSE: 31.571025829261924\n",
      "Weights (Coefficients): [-0.006407502817827284, -0.000441852220629118, 0.0006417758801631978, -0.0005267275991136151, -0.0046306790800415415, -0.00020850561142950294, 0.0029584201429184546, 0.005489645193283423, -0.0058712230222778055, 0.0016590640278298832, -0.008567705912449397, 0.0016288220925649993, 0.0009839553054340241, 0.0009096939826755653, 0.0013459341030587215, -0.0003100852051924702, -0.0017992124505995634, 0.006003476119283545, 0.003612712892085592, -0.001482857191159912, 0.000474324225762451, 0.0038328170474348456, -0.003215714251586564, -0.003497809482989227]\n",
      "Intercepts: [-232.8462601605469, -411.8849098776417, -478.7604909536814, -494.37085627154664, -445.32378770987253, -507.3748282331888, -476.1520169191844, -215.94122000737747, -282.95401253625465, -359.7383813984602, -118.55326942270815, -621.0666061560222, -474.253725061973, -472.6217447040115, -533.7507733960992, -505.656219657985, -443.2139707540818, -557.9315454838455, -494.94338482565536, -104.07944948841296, -109.60040476271175, -603.5238252921689, -516.2142985686153, -442.5704715932637]\n"
     ]
    }
   ],
   "source": [
    "# Leave-One-Out Cross-Validation \n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# define model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "\n",
    "# list to calculate RSME\n",
    "errors = []\n",
    "weights = []  \n",
    "intercepts = []  \n",
    "\n",
    "# loop to do the leave one out\n",
    "for train_index, test_index in loo.split(X):\n",
    "    # split the data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # learn the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    weights.append(model.coef_[0])  \n",
    "    intercepts.append(model.intercept_)\n",
    "    \n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # add the error to the list\n",
    "    error = np.sqrt(mean_squared_error(y_test, y_pred))  # RMSE\n",
    "    errors.append(error)\n",
    "\n",
    "# caculate the average\n",
    "mean_rmse = np.mean(errors)\n",
    "\n",
    "print(f\"Individual RMSEs: {errors}\")\n",
    "print(f\"Mean RMSE: {mean_rmse}\")\n",
    "print(f\"Weights (Coefficients): {weights}\")\n",
    "print(f\"Intercepts: {intercepts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "1. no need to do grid search\n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual RMSEs: [11.982451969205286, 0.1269567617616758, 15.330870823196463, 4.9806056080218895, 0.8091682898960926, 4.283951676079283, 18.643427940983827, 7.1315144310981395, 5.624318390788858, 18.923556918861323, 7.719751974091963, 19.447310425905556, 4.028691402284011, 13.807453977085046, 13.27131286676773, 4.879168198811385, 5.906741810148574, 2.8808268571684152, 16.321209075321775, 7.225603746520662, 34.844535288585824, 5.227746230602463, 9.39131856313918, 10.260775557506904]\n",
      "Mean RMSE: 10.127052865993013\n",
      "Weights (Coefficients): [-0.3966080519687018, -0.16730427521292512, 0.02073695961087896, -0.10736806291323153, -0.19548021866783138, -0.26636287330288133, 0.09831798804486057, -0.5526664612887832, -0.30822156654314603, 0.12543748801194046, -0.3978252267799436, -0.06590183506121514, -0.16460732769617195, -0.15034840743618247, -0.10881523509369588, -0.22310539939590893, -0.11960637388608134, -0.11017049101252849, -0.4184619836889878, 0.007091300208744331, -0.2726192752774813, -0.14751874590534206, 0.10924191876176378, -0.32636690232083393]\n",
      "Intercepts: [132.51683457125952, 132.79875495833878, 52.58645072315323, 106.43582049250128, 129.61988189023123, 158.5142535919931, 96.23296493299011, 114.46308492353847, 169.7041152435727, 136.90525058762287, 157.0580148913939, 101.47708023967641, 139.85960060549715, 122.85357847789388, 111.32326862844121, 142.94689450576618, 145.01007791049162, 121.78934870338576, 193.85399430067096, 117.71081556214097, 95.01557830482237, 139.18714710709153, 91.56915038113324, 136.33717582384637]\n"
     ]
    }
   ],
   "source": [
    "# Leave-One-Out Cross-Validation \n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# define model\n",
    "from sklearn.linear_model import Lasso\n",
    "model = Lasso(alpha=2.1544346900318822e-07)\n",
    "\n",
    "## set the grid search\n",
    "#param_grid = {'alpha': np.logspace(-10, -4, 10)}  # alphaの値を0.001から10まで対数スケールで探索\n",
    "#lasso = Lasso()\n",
    "#\n",
    "## use MSE as the evaluation score\n",
    "#def neg_rmse(y_true, y_pred):\n",
    "#    return -np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "#\n",
    "#scorer = make_scorer(neg_rmse)\n",
    "#\n",
    "## execute grid search\n",
    "#grid_search = GridSearchCV(estimator=lasso, param_grid=param_grid, cv=loo, scoring=scorer)\n",
    "#grid_search.fit(X, y)\n",
    "#\n",
    "## show the result\n",
    "#print(\"Best Parameters:\", grid_search.best_params_)\n",
    "#print(\"Best RMSE:\", grid_search.best_score_)\n",
    "#print(\"All Results:\")\n",
    "#for params, mean_test_score in zip(grid_search.cv_results_['params'], grid_search.cv_results_['mean_test_score']):\n",
    "#    print(f\"alpha: {params['alpha']}, RMSE: {mean_test_score}\")\n",
    "\n",
    "\n",
    "# list to calculate RSME\n",
    "errors = []\n",
    "weights = []  \n",
    "intercepts = []  \n",
    "\n",
    "# loop to do the leave one out\n",
    "for train_index, test_index in loo.split(X):\n",
    "    # split the data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # learn the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    weights.append(model.coef_[0])  \n",
    "    intercepts.append(model.intercept_)\n",
    "    \n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # add the error to the list\n",
    "    error = np.sqrt(mean_squared_error(y_test, y_pred))  # RMSE\n",
    "    errors.append(error)\n",
    "\n",
    "# caculate the average\n",
    "mean_rmse = np.mean(errors)\n",
    "\n",
    "print(f\"Individual RMSEs: {errors}\")\n",
    "print(f\"Mean RMSE: {mean_rmse}\")\n",
    "print(f\"Weights (Coefficients): {weights}\")\n",
    "print(f\"Intercepts: {intercepts}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "1. The model will converge below the alpha = 1e-4, so the range of grid search will be 1e-10~1e-4.\n",
    "2. The best parameter is 2.1544346900318822e-07.\n",
    "3. No doubt that the Lasso is better than the linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual RMSEs: [2.9891111111111037, 0.898315476190473, 0.26828571428571735, 2.445293650793646, 2.664255952380951, 1.163559523809523, 1.3362341269841256, 1.825523809523812, 0.6137678571428555, 1.1499960317460278, 3.888932900432902, 0.6811428571428593, 0.8572261904761911, 0.7040714285714262, 1.3970238095238088, 0.03079365079365104, 1.502426587301585, 0.734666666666671, 3.3225972222222193, 0.32642857142857906, 4.31979166666666, 0.38538095238095593, 2.2212916666666658, 2.5086924603174623]\n",
      "Mean RMSE: 1.593117078523328\n",
      "Feature Importances: [0.002386125065212781, 0.001682174897408351, 0.0011466841630689243, 0.0009375636528740214, 0.0014167613858935353, 0.0010803061936910854, 0.0011636146845574308, 0.0017801974875295782, 0.0007541526333800193, 0.0008539176802156372, 0.0006725432960132843, 0.0013734988567772263, 0.0017353765935551114, 0.0013464002885213476, 0.0013791713764291621, 0.000982200053372363, 0.0012871733359278395, 0.0013185914038109864, 0.0011335271017208662, 0.0007547260383856773, 0.0010753761908277838, 0.001133128155180854, 0.0015140410036304495, 0.00118921467076803]\n",
      "Predictions: [19.010888888888896, 7.101684523809527, 18.268285714285717, 15.445293650793646, 5.664255952380951, 4.836440476190477, 8.336234126984126, 17.825523809523812, 5.6137678571428555, 18.850003968253972, 4.888932900432902, 8.31885714285714, 4.857226190476191, 14.704071428571426, 8.602976190476191, 18.96920634920635, 18.502426587301585, 14.265333333333329, 15.32259722222222, 20.67357142857142, 19.68020833333334, 11.385380952380956, 4.221291666666666, 20.491307539682538]\n"
     ]
    }
   ],
   "source": [
    "# Leave-One-Out Cross-Validation \n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# define model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(max_depth= 3, min_samples_split= 2, n_estimators= 200,random_state=42)\n",
    "\n",
    "## set grid search\n",
    "#param_grid = {\n",
    "#    'n_estimators': [50, 100, 200],  # the number of trees\n",
    "#    'max_depth': [None, 3, 5],       # the depth\n",
    "#    'min_samples_split': [2, 5]     # samples needed to split\n",
    "#}\n",
    "#\n",
    "## initialize random forest\n",
    "#rf = RandomForestRegressor(random_state=42)\n",
    "#loo = LeaveOneOut()\n",
    "#\n",
    "## use RMSE as the evaluation metric\n",
    "#def neg_rmse(y_true, y_pred):\n",
    "#    return -np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "#\n",
    "#scorer = make_scorer(neg_rmse)\n",
    "#\n",
    "## do grid search\n",
    "#grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=loo, scoring=scorer)\n",
    "#grid_search.fit(X, y)\n",
    "#\n",
    "## show the result\n",
    "#print(\"Best Parameters:\", grid_search.best_params_)\n",
    "#print(\"Best RMSE:\", -grid_search.best_score_)  \n",
    "#print(\"All Results:\")\n",
    "#for params, mean_test_score in zip(grid_search.cv_results_['params'], grid_search.cv_results_['mean_test_score']):\n",
    "#    print(f\"Params: {params}, RMSE: {-mean_test_score}\") # reverse the negative score\n",
    "\n",
    "\n",
    "# list to calculate RSME\n",
    "errors = []\n",
    "feature_importances = [] \n",
    "predictions = []  \n",
    "\n",
    "# loop to do the leave one out\n",
    "for train_index, test_index in loo.split(X):\n",
    "    # split the data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # learn the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    feature_importances.append(model.feature_importances_[0])\n",
    "    \n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions.append(y_pred[0])\n",
    "    \n",
    "    # add the error to the list\n",
    "    error = np.sqrt(mean_squared_error(y_test, y_pred))  # RMSE\n",
    "    errors.append(error)\n",
    "\n",
    "# caculate the average\n",
    "mean_rmse = np.mean(errors)\n",
    "\n",
    "print(f\"Individual RMSEs: {errors}\")\n",
    "print(f\"Mean RMSE: {mean_rmse}\")\n",
    "print(f\"Feature Importances: {feature_importances}\")\n",
    "print(f\"Predictions: {predictions}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "1. So far, the random forest is the SOTA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual RMSEs: [0.6000000000000014, 1.8000000000000007, 3.0, 3.5, 0.6000000000000001, 3.0, 3.0, 0.5999999999999996, 1.7999999999999998, 1.8000000000000007, 3.5, 0.5999999999999996, 0.6000000000000001, 1.8000000000000007, 0.5999999999999996, 3.0, 1.8000000000000007, 0.5999999999999996, 3.5, 0.6000000000000014, 3.0, 1.8000000000000007, 1.7999999999999998, 1.8000000000000007]\n",
      "Mean RMSE: 1.8625\n",
      "Predictions: [21.4, 9.8, 15.0, 16.5, 3.6, 3.0, 10.0, 15.4, 3.2, 21.8, 4.5, 9.6, 3.4, 15.8, 9.4, 22.0, 15.2, 15.6, 15.5, 21.6, 21.0, 9.2, 3.8, 21.2]\n"
     ]
    }
   ],
   "source": [
    "# Leave-One-Out Cross-Validation \n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# define model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor(max_depth = None, min_samples_leaf = 1, min_samples_split =  10, random_state=42)\n",
    "\n",
    "\n",
    "## set grid research\n",
    "#param_grid = {\n",
    "#    'max_depth': [None, 2, 3, 5],        \n",
    "#    'min_samples_split': [2, 5, 10],   \n",
    "#    'min_samples_leaf': [1, 2, 4]   \n",
    "#}\n",
    "#\n",
    "## initialize decision tree\n",
    "#dt = DecisionTreeRegressor(random_state=42)\n",
    "#loo = LeaveOneOut()\n",
    "#\n",
    "## same as above\n",
    "#def neg_rmse(y_true, y_pred):\n",
    "#    return -np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "#\n",
    "#scorer = make_scorer(neg_rmse)\n",
    "#\n",
    "#grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=loo, scoring=scorer)\n",
    "#grid_search.fit(X, y)\n",
    "#\n",
    "#print(\"Best Parameters:\", grid_search.best_params_)\n",
    "#print(\"Best RMSE:\", -grid_search.best_score_) \n",
    "#print(\"All Results:\")\n",
    "#for params, mean_test_score in zip(grid_search.cv_results_['params'], grid_search.cv_results_['mean_test_score']):\n",
    "#    print(f\"Params: {params}, RMSE: {-mean_test_score}\")  \n",
    "\n",
    "\n",
    "# list to calculate RSME\n",
    "errors = []\n",
    "predictions = []  \n",
    "\n",
    "# loop to do the leave one out\n",
    "for train_index, test_index in loo.split(X):\n",
    "    # split the data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # learn the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions.append(y_pred[0])\n",
    "    \n",
    "    # add the error to the list\n",
    "    error = np.sqrt(mean_squared_error(y_test, y_pred))  # RMSE\n",
    "    errors.append(error)\n",
    "\n",
    "# caculate the average\n",
    "mean_rmse = np.mean(errors)\n",
    "\n",
    "print(f\"Individual RMSEs: {errors}\")\n",
    "print(f\"Mean RMSE: {mean_rmse}\")\n",
    "print(f\"Predictions: {predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "1. The result is better than the Lasso.\n",
    "2. A little bit lower than the Random Forest, ,which makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual RMSEs: [9.364964943601171, 3.554936067260634, 5.177361825052316, 1.1236253064041541, 9.077964570739613, 7.514658119484697, 6.870760667652064, 3.9636953344949237, 8.297987048378229, 8.180267115171453, 12.244660752633623, 1.3952289740076047, 7.219526706557851, 3.2529605214684363, 3.071433481263851, 5.872459145917034, 4.5025259762789105, 2.4770788009097586, 1.4826758835703444, 8.404001079137725, 12.031417772381994, 1.9994202954357156, 11.823605270440499, 10.038632257298241]\n",
      "Mean RMSE: 6.205910329814202\n",
      "Predictions: [12.635035056398829, 11.554936067260634, 12.822638174947684, 14.123625306404154, 12.077964570739613, 13.514658119484697, 13.870760667652064, 12.036304665505076, 13.297987048378229, 11.819732884828547, 13.244660752633623, 7.604771025992395, 11.21952670655785, 10.747039478531564, 13.07143348126385, 13.127540854082966, 12.49747402372109, 12.522921199090241, 13.482675883570344, 12.595998920862275, 11.968582227618006, 12.999420295435716, 13.823605270440499, 12.961367742701759]\n"
     ]
    }
   ],
   "source": [
    "# Leave-One-Out Cross-Validation \n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# define model\n",
    "from sklearn.svm import SVR\n",
    "model = SVR(C = 10, epsilon =  0.01, kernel = 'rbf')\n",
    "\n",
    "## scaling the features\n",
    "#scaler = StandardScaler()\n",
    "#X_scaled = scaler.fit_transform(X)\n",
    "#\n",
    "## set grid research\n",
    "#param_grid = {\n",
    "#    'C': [0.1, 1, 10, 100],         \n",
    "#    'epsilon': [0.01, 0.1, 0.2],  \n",
    "#    'kernel': ['linear', 'rbf']     \n",
    "#}\n",
    "#\n",
    "## initial SVR\n",
    "#svr = SVR()\n",
    "#loo = LeaveOneOut()\n",
    "#\n",
    "#def neg_rmse(y_true, y_pred):\n",
    "#    return -np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "#\n",
    "#scorer = make_scorer(neg_rmse)\n",
    "#\n",
    "#grid_search = GridSearchCV(estimator=svr, param_grid=param_grid, cv=loo, scoring=scorer)\n",
    "#grid_search.fit(X_scaled, y)\n",
    "#\n",
    "#\n",
    "#print(\"Best Parameters:\", grid_search.best_params_)\n",
    "#print(\"Best RMSE:\", -grid_search.best_score_) \n",
    "#print(\"All Results:\")\n",
    "#for params, mean_test_score in zip(grid_search.cv_results_['params'], grid_search.cv_results_['mean_test_score']):\n",
    "#    print(f\"Params: {params}, RMSE: {-mean_test_score}\")  \n",
    "\n",
    "# list to calculate RSME\n",
    "errors = []\n",
    "predictions = []  \n",
    "\n",
    "# loop to do the leave one out\n",
    "for train_index, test_index in loo.split(X):\n",
    "    # split the data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # learn the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions.append(y_pred[0])\n",
    "    \n",
    "    # add the error to the list\n",
    "    error = np.sqrt(mean_squared_error(y_test, y_pred))  # RMSE\n",
    "    errors.append(error)\n",
    "\n",
    "# caculate the average\n",
    "mean_rmse = np.mean(errors)\n",
    "\n",
    "print(f\"Individual RMSEs: {errors}\")\n",
    "print(f\"Mean RMSE: {mean_rmse}\")\n",
    "print(f\"Predictions: {predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "1. It needs to explore more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
