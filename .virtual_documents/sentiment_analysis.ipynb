import pandas as pd


df = pd.read_csv('sentiment_dataset/reddit_data.csv')





from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
# Initialize the sentiment analyzer
analyzer = SentimentIntensityAnalyzer()


# Using texts for sentiment analysis
neighborhood_score = {}
for index, row in df.iterrows():
    sentiment = analyzer.polarity_scores(row['text'])
    if row['neighborhood'] in neighborhood_score.keys():
        neighborhood_score[row['neighborhood']] += sentiment['compound']
    else:
        neighborhood_score[row['neighborhood']] = 0
        neighborhood_score[row['neighborhood']] += sentiment['compound']


# take the avergae
for area in neighborhood_score:
    count = df[df['neighborhood'] == area].shape[0]
    neighborhood_score[area] /= count


# make dataframe
df_vader = pd.DataFrame(list(neighborhood_score.items()), columns=['Neighborhood', 'OverallScore'])
df_vader = df_vader.sort_values(by='OverallScore',ascending = False).reset_index(drop=True)


# save
vader_path = 'sentiment_result/vader_sentiment.csv'
df_vader.to_csv(vader_path, index=False)





from textblob import TextBlob


# Using texts for sentiment analysis
polarity_score = {}
subjectivity_score = {}
for index, row in df.iterrows():
    blob = TextBlob(row['text'])
    sentiment = blob.sentiment
    if row['neighborhood'] in polarity_score.keys():
        polarity_score[row['neighborhood']] += sentiment.polarity
        subjectivity_score[row['neighborhood']] += sentiment.subjectivity
    else:
        polarity_score[row['neighborhood']] = 0
        polarity_score[row['neighborhood']] += sentiment.polarity
        subjectivity_score[row['neighborhood']] = 0
        subjectivity_score[row['neighborhood']] += sentiment.subjectivity


# take the average
for area in polarity_score:
    count = df[df['neighborhood'] == area].shape[0]
    polarity_score[area] /= count
    subjectivity_score[area] /= count


area_list = []
for area in polarity_score:
    area_list.append(tuple([area,polarity_score[area],subjectivity_score[area]]))


# make dataframe
df_textbolb = pd.DataFrame(area_list, columns=['Neighborhood', 'PolarityScore','SubjectivityScore'])
df_textbolb = df_textbolb.sort_values(by='PolarityScore',ascending = False).reset_index(drop=True)


# save
textbolb_path = 'sentiment_result/textbolb_sentiment.csv'
df_textbolb.to_csv(textbolb_path, index=False)





from afinn import Afinn
# Initialize the sentiment analyzer
afinn = Afinn()


# Using texts for sentiment analysis
neighborhood_score = {}
for index, row in df.iterrows():
    score = afinn.score(row['text'])
    if row['neighborhood'] in neighborhood_score.keys():
        neighborhood_score[row['neighborhood']] += score
    else:
        neighborhood_score[row['neighborhood']] = 0
        neighborhood_score[row['neighborhood']] += score


# take the avergae
for area in neighborhood_score:
    count = df[df['neighborhood'] == area].shape[0]
    neighborhood_score[area] /= count


# make dataframe
df_afinn = pd.DataFrame(list(neighborhood_score.items()), columns=['Neighborhood', 'SentimentScore'])
df_afinn = df_afinn.sort_values(by='SentimentScore',ascending = False).reset_index(drop=True)


# save
afinn_path = 'sentiment_result/afinn_sentiment.csv'
df_afinn.to_csv(afinn_path, index=False)



